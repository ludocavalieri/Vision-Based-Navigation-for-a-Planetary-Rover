# Vision-Based-Navigation-for-a-Planetary-Rover

Communication and computing performances of planetary rovers limit their autonomous traverse distances. Moreover, for missions to Mars, manual driving is unfeasible: not only does the round trip communication time between Earth and Mars takes from 5 to 20 minutes, but contact with ground can be reached only twice per Sol. Even with the help of orbital data, planning long traverses, and avoiding all local obstacles the rover may encounter on its path, proves to be nearly an impossible task. Such rovers are expensive and out of reach for physical help, and therefore, any collision critically endangers the mission's success. Neverthless, considering future missions' programs, there is the necessity for a high degree of autonomy of these robotic assets.

This work aims to develop an algorithm for autonomous localization and mapping of a planetary rover employing the images provided by a stereocamera. The focus of the study will be on the computer vision techniques that are able to provide useful information for the navigation task, but the particular topic of the rover guidance will not be tackled. In the context of our specific application, great attention will be given to the efficiency of the proposed algorithm and its ability to run in real time.

In particular, the rover trajectory and pose will be reconstructed using Visual Odometry. Then, an obstacle detection algorithm will be employed to identify and locate possible hazardous objects in the rover frame. In this context, different O.D. techniques will be surveyed in order to test their performances. 

The ultimate output of the pipeline will be a medium-to-close range obstacle map reconstructed entirely from stereo camera data. The overall performances will be evaluated comparing the ground truth trajectory and obstacle map with the reconstructed ones.
